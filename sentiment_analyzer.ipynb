{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "virtual environment 'sent.analyzer'\n",
    "\n",
    "    conda install -n sent.analyzer spacy\n",
    "    python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Successfully built en-core-web-sm\n",
    "\n",
    "    Installing collected packages: en-core-web-sm\n",
    "\n",
    "    Successfully installed en-core-web-sm-2.3.1\n",
    "\n",
    "    [+] Download and installation successful\n",
    "\n",
    "    You can now load the model via spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing\n",
    "Tokenization is the process of breaking down chunks of text into smaller pieces. spaCy comes with a default processing pipeline that begins with tokenization, making this process a snap. In spaCy, you can do either sentence tokenization or word tokenization:\n",
    "\n",
    "    Word tokenization breaks text down into individual words.\n",
    "    Sentence tokenization breaks text down into individual sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Dave watched as the forest burned up on the hill,\n",
    "only a few miles from his house. The car had\n",
    "been hastily packed and Marta was inside trying to round\n",
    "up the last of the pets. \"Where could she be?\" he wondered\n",
    "as he continued to wait for Marta to appear with the pets.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = [token for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[,\n",
       " Dave,\n",
       " watched,\n",
       " as,\n",
       " the,\n",
       " forest,\n",
       " burned,\n",
       " up,\n",
       " on,\n",
       " the,\n",
       " hill,\n",
       " ,,\n",
       " ,\n",
       " only,\n",
       " a,\n",
       " few,\n",
       " miles,\n",
       " from,\n",
       " his,\n",
       " house,\n",
       " .,\n",
       " The,\n",
       " car,\n",
       " had,\n",
       " ,\n",
       " been,\n",
       " hastily,\n",
       " packed,\n",
       " and,\n",
       " Marta,\n",
       " was,\n",
       " inside,\n",
       " trying,\n",
       " to,\n",
       " round,\n",
       " ,\n",
       " up,\n",
       " the,\n",
       " last,\n",
       " of,\n",
       " the,\n",
       " pets,\n",
       " .,\n",
       " \",\n",
       " Where,\n",
       " could,\n",
       " she,\n",
       " be,\n",
       " ?,\n",
       " \",\n",
       " he,\n",
       " wondered,\n",
       " ,\n",
       " as,\n",
       " he,\n",
       " continued,\n",
       " to,\n",
       " wait,\n",
       " for,\n",
       " Marta,\n",
       " to,\n",
       " appear,\n",
       " with,\n",
       " the,\n",
       " pets,\n",
       " .,\n",
       " ]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[,\n",
       " Dave,\n",
       " watched,\n",
       " forest,\n",
       " burned,\n",
       " hill,\n",
       " ,,\n",
       " ,\n",
       " miles,\n",
       " house,\n",
       " .,\n",
       " car,\n",
       " ,\n",
       " hastily,\n",
       " packed,\n",
       " Marta,\n",
       " inside,\n",
       " trying,\n",
       " round,\n",
       " ,\n",
       " pets,\n",
       " .,\n",
       " \",\n",
       " ?,\n",
       " \",\n",
       " wondered,\n",
       " ,\n",
       " continued,\n",
       " wait,\n",
       " Marta,\n",
       " appear,\n",
       " pets,\n",
       " .,\n",
       " ]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens = [token for token in doc if not token.is_stop]\n",
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Token: \\n, lemma: \\n',\n",
       " 'Token: Dave, lemma: Dave',\n",
       " 'Token: watched, lemma: watch',\n",
       " 'Token: forest, lemma: forest',\n",
       " 'Token: burned, lemma: burn',\n",
       " 'Token: hill, lemma: hill',\n",
       " 'Token: ,, lemma: ,',\n",
       " 'Token: \\n, lemma: \\n',\n",
       " 'Token: miles, lemma: mile',\n",
       " 'Token: house, lemma: house',\n",
       " 'Token: ., lemma: .',\n",
       " 'Token: car, lemma: car',\n",
       " 'Token: \\n, lemma: \\n',\n",
       " 'Token: hastily, lemma: hastily',\n",
       " 'Token: packed, lemma: pack',\n",
       " 'Token: Marta, lemma: Marta',\n",
       " 'Token: inside, lemma: inside',\n",
       " 'Token: trying, lemma: try',\n",
       " 'Token: round, lemma: round',\n",
       " 'Token: \\n, lemma: \\n',\n",
       " 'Token: pets, lemma: pet',\n",
       " 'Token: ., lemma: .',\n",
       " 'Token: \", lemma: \"',\n",
       " 'Token: ?, lemma: ?',\n",
       " 'Token: \", lemma: \"',\n",
       " 'Token: wondered, lemma: wonder',\n",
       " 'Token: \\n, lemma: \\n',\n",
       " 'Token: continued, lemma: continue',\n",
       " 'Token: wait, lemma: wait',\n",
       " 'Token: Marta, lemma: Marta',\n",
       " 'Token: appear, lemma: appear',\n",
       " 'Token: pets, lemma: pet',\n",
       " 'Token: ., lemma: .',\n",
       " 'Token: \\n, lemma: \\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = [f'Token: {token}, lemma: {token.lemma_}' for token in filtered_tokens]\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Your Own NLP Sentiment Analyzer\n",
    "From the previous sections, you’ve probably noticed four major stages of building a sentiment analysis pipeline:\n",
    "\n",
    "    Loading data\n",
    "    Preprocessing\n",
    "    Training the classifier\n",
    "    Classifying data\n",
    "    \n",
    "For building a real-life sentiment analyzer, you’ll work through each of the steps that compose these stages. You’ll use the Large Movie Review Dataset compiled by Andrew Maas to train and test your sentiment analyzer. Once you’re ready, proceed to the next section to load your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(\n",
    "    data_directory: str = \"aclImdb/train\",\n",
    "    split: float = 0.8,\n",
    "    limit: int = 0\n",
    ") -> tuple:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to iterate through all the files in the dataset and load them into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_training_data(data_directory: str = \"aclImdb/train\",split: float = 0.8,limit: int = 0) -> tuple:\n",
    "    \"\"\"\n",
    "    Split (float) is the proportion of data used to train, remainder tests\n",
    "    \"\"\"\n",
    "    #load from files\n",
    "    reviews = []\n",
    "    for label in [\"pos\", \"neg\"]:\n",
    "        labeled_directory = f\"{data_directory}/{label}\"\n",
    "        for review in os.listdir(labeled_directory):\n",
    "            if review.endswith(\".txt\"):\n",
    "                with open(f\"{labeled_directory}/{review}\") as f:\n",
    "                          text = f.read()\n",
    "                          text = text.replace(\"<br />\", \"\\n\\n\")\n",
    "                          if text.strip():\n",
    "                              spacy_label = {\n",
    "                                  \"cats\": {\n",
    "                                      \"pos\": \"pos\" == label,\n",
    "                                      \"neg\": \"neg\" == label\n",
    "                                  }}\n",
    "                              reviews.append((text,spacy_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Below randomly shuffle the order of the reviews to reduce the possible bias produced from loading order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "def load_training_data(data_directory: str = \"aclImdb/train\",split: float = 0.8,limit: int = 0) -> tuple:\n",
    "    \"\"\"\n",
    "    Split (float) is the proportion of data used to train, remainder tests\n",
    "    \"\"\"\n",
    "    #load from files\n",
    "    reviews = []\n",
    "    for label in [\"pos\", \"neg\"]:\n",
    "        labeled_directory = f\"{data_directory}/{label}\"\n",
    "        for review in os.listdir(labeled_directory):\n",
    "            if review.endswith(\".txt\"):\n",
    "                with open(f\"{labeled_directory}/{review}\") as f:\n",
    "                          text = f.read()\n",
    "                          text = text.replace(\"<br />\", \"\\n\\n\")\n",
    "                          if text.strip():\n",
    "                              spacy_label = {\n",
    "                                  \"cats\": {\n",
    "                                      \"pos\": \"pos\" == label,\n",
    "                                      \"neg\": \"neg\" == label\n",
    "                                  }}\n",
    "                              reviews.append((text,spacy_label))\n",
    "    random.shuffle(reviews)\n",
    "    \n",
    "    if limit:\n",
    "        reviews = reviews[:limit]\n",
    "    split = int(len(reviews) * split)\n",
    "    return reviews[:split], reviews[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Your Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the spaCy pipeline together allows you to rapidly build and train a convolutional neural network (CNN) for classifying text data. \n",
    "    \n",
    "    1. Modifying the base spaCy pipeline to include the textcat component\n",
    "    2. Building a training loop to train the textcat component\n",
    "    3. Evaluating the progress of your model training after a given number of training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(training_data: list, test_data: list, iterations: int = 20) -> None:\n",
    "    #Build Pipline\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    if \"textcat\" not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe(\n",
    "            \"textcat\", config = {\"architecture\": \"simple_cnn\"}\n",
    "        )\n",
    "        nlp.add_pipe(textcat, last = True)\n",
    "    else:\n",
    "        textcat = nlp.get_pipe(\"textcat\")\n",
    "    \n",
    "    textcat.add_label(\"pos\")\n",
    "    textcat.add_label(\"neg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Your Training Loop to Train textcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(training_data: list, test_data: list, iterations: int= 20) -> None:\n",
    "    #Build Pipeline\n",
    "    nlp = spacy.load('en_core_web_sm') # load the english model\n",
    "    if \"textcat\" not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe(\"textcat\", config = {\"architecture\": \"simple_cnn\"})\n",
    "        nlp.add_pipe(textcat,last=True)\n",
    "    else:\n",
    "        textcat = nlp.get_pipe('textcat')\n",
    "    \n",
    "    textcat.add_label(\"pos\")\n",
    "    textcat.add_label('neg')\n",
    "    \n",
    "    #Train only textcat\n",
    "    training_excluded_pipes = [pipe for pip3 in nlp.pipe_names if pipe != \"textcat\"]\n",
    "    \n",
    "    with nlp.disable_pips(training_excluded_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        # Training loop\n",
    "        print(\"Beginning Training\")\n",
    "        print(\"Loss\\tPrecision\\tRecall\\tF-score\")\n",
    "        batch_sizes = compounding(4.0,32.0,1.001) # a generator that yields infinite series of input numbers\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            loss = {}\n",
    "            random.shuffle(training_data)\n",
    "            batches = minibatch(training_data,size = batch_sizes)\n",
    "            for batch in batches:\n",
    "                text, labels = zip(*batch)\n",
    "                nlp.update(\n",
    "                    text,\n",
    "                    labels,\n",
    "                    drop = 0.2,\n",
    "                    sgd = optimizer,\n",
    "                    losses = loss\n",
    "                )\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                evaluations_results = evaluate_model(tokenizer = nlp.tokenizer,textcat=textcat,test_data = test_data) #evaluate model function\n",
    "                \n",
    "                print(\n",
    "                    f\"{loss['textcat']}\\t{evaluation_results['precision']}\"\n",
    "                    f\"\\t{evaluation_results['recall']}\"\n",
    "                    f\"\\t{evaluation_results['f-score']}\"\n",
    "                )\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Progress of Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(tokenizer,textcat,test_data:list) -> dict:\n",
    "    reviews, labels = zip(*test_data)\n",
    "    reviews = (tokenizer(review) for review in reviews)\n",
    "    true_positives = 0\n",
    "    false_positives = 1e-8 #can't be 0 because of the presence in denominator\n",
    "    true_negatives = 0\n",
    "    false_negatives = 1e-8\n",
    "    \n",
    "    for i,review in enumerate(textcat.pipe(reviews)):\n",
    "        true_label = labels[i]\n",
    "        for predicted_label, score in review.cats.items()\n",
    "        #every category's dictionary includes both labels. You can get all the info you need with just the positive label\n",
    "        if predicted_label = \"neg\":\n",
    "            continue\n",
    "        \n",
    "        if score >= 0.5 and true_label[\"pos\"]:\n",
    "            true_positives +=1\n",
    "        elif score >= 0.5 and true_label[\"neg\"]:\n",
    "            false_positives += 1\n",
    "        elif score <0.5 and true_label[\"neg\"]:\n",
    "            true_negatives +=1\n",
    "        elif score < 0.5 and true_label[\"pos\"]:\n",
    "            false_negatives +=1\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        f_score = 0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"precision\": precision, \"recall\":recall,\"f-score\":f_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(training_data: list, test_data: list, iterations: int= 20) -> None:\n",
    "    #Build Pipeline\n",
    "    nlp = spacy.load('en_core_web_sm') # load the english model\n",
    "    if \"textcat\" not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe(\"textcat\", config = {\"architecture\": \"simple_cnn\"})\n",
    "        nlp.add_pipe(textcat,last=True)\n",
    "    else:\n",
    "        textcat = nlp.get_pipe('textcat')\n",
    "    \n",
    "    textcat.add_label(\"pos\")\n",
    "    textcat.add_label('neg')\n",
    "    \n",
    "    #Train only textcat\n",
    "    training_excluded_pipes = [pipe for pip3 in nlp.pipe_names if pipe != \"textcat\"]\n",
    "    \n",
    "    with nlp.disable_pips(training_excluded_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        # Training loop\n",
    "        print(\"Beginning Training\")\n",
    "        print(\"Loss\\tPrecision\\tRecall\\tF-score\")\n",
    "        batch_sizes = compounding(4.0,32.0,1.001) # a generator that yields infinite series of input numbers\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            loss = {}\n",
    "            random.shuffle(training_data)\n",
    "            batches = minibatch(training_data,size = batch_sizes)\n",
    "            for batch in batches:\n",
    "                text, labels = zip(*batch)\n",
    "                nlp.update(\n",
    "                    text,\n",
    "                    labels,\n",
    "                    drop = 0.2,\n",
    "                    sgd = optimizer,\n",
    "                    losses = loss\n",
    "                )\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                evaluations_results = evaluate_model(tokenizer = nlp.tokenizer,textcat=textcat,test_data = test_data) #evaluate model function\n",
    "                \n",
    "                print(\n",
    "                    f\"{loss['textcat']}\\t{evaluation_results['precision']}\"\n",
    "                    f\"\\t{evaluation_results['recall']}\"\n",
    "                    f\"\\t{evaluation_results['f-score']}\"\n",
    "                )\n",
    "    #Save model\n",
    "    with nlp.use_params(optimizer.averages):\n",
    "        nlp.to_disk(\"model_artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "sentiment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
